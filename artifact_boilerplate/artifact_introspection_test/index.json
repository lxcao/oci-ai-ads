{
  "service_packs":
  [
    {
      "slug": "classic_cpu",
      "name": "Classic CPU Notebook Session Kernel",
      "version": "1.0",
      "manifest_version": "1.0",
      "python": "3.6",
      "arch_type": "CPU",
      "deprecated": "True",
      "libraries": ["ads (v0+untagged.4506.g5075d66)", "mlx (v1.0.11)", "automl (v0.4.2)", "dask (v2.16)", "scikit-learn (v0.21.3)", "tensorflow (v2.0)", "pytorch-cpu (v1.0.1)", "mxnet (v1.5)", "xgboost (v0.90)", "lightgbm (v2.3)", "pyod (v0.7.7)", "pymc3 (v3.7)"],
      "description": "This conda environment **(deprecated Oct 2021)** corresponds to the CPU notebook session available in our most recent prior release (August 2020) and will be deprecated by October 2021. We provide this conda as a starting point to help migrate work to the other modular conda environments. There will be no further updates to this conda environment.To get started with the Classic CPU environment, open and review the notebook example **notebooks/classic_cpu/getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "logo": "v5logo",
      "root": "False",
      "notebooks": ["notebooks/v5pack/"],
      "type": "data_science",
      "create_date": "Fri, Dec 11, 2020, 00:56:41  UTC",
      "size_mb": "1842.45",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Classic CPU Notebook Session Kernel/1.0/classic_cpu", "oci://service_conda_packs@ociodscdev/service_pack/cpu/Data Exploration and Manipulation for CPU Python 3.7/1.0/dataexpl_p37_cpu_v1"]
    },
    {
      "arch_type": "CPU",
      "description": "The Data Exploration conda environment contains libraires for ingesting, processing, and visualizing datasets. Oracle ADS (lite version) comes pre-installed to help you  ingest data from multiple data sources on OCI. You can also consume streams from the Streaming service using the kafka-python library. You can work on dataframes  using pandas, pandarallel, and dask. Use matplotlib, seaborn, plotly, and bokeh to construct visualizations of your dataset. To get started with the Data Exploration environment, review the notebook example **getting-started.ipynb** in the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "pandas (v1.2.3)", "pandarallel (v1.5.1)", "dask (v2.30.0)", "kafka-python (v2.0.0)", "seaborn (v0.10.1)", "matplotlib (v3.3.1)", "plotly (v4.9.0)"],
      "logo": "data_exploration",
      "manifest_version": "1.0",
      "name": "Data Exploration and Manipulation for CPU Python 3.7",
      "notebooks": ["notebooks/dataexpl_p37_cpu_v1/"],
      "python": "3.7",
      "slug": "dataexpl_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Wed, May 26, 2021, 21:32:13  UTC",
      "size_mb": "412.71",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Data Exploration and Manipulation for CPU Python 3.7/1.0/dataexpl_p37_cpu_v1"]
    },
    {
      "slug": "explv1",
      "name": "Data Exploration and Manipulation",
      "version": "1.0",
      "manifest_version": "1.0",
      "python": "3.6",
      "arch_type": "CPU",
      "libraries": ["ads-lite (v2.1.0)", "oci (v2.21.3)", "pandas (v1.1)", "pandarallel (v1.5.1)", "dask (v2.16)", "kafka-python (v2.0.0)", "seaborn (v0.10.1)", "matplotlib (v3.3.1)", "plotly (v4.9.0)"],
      "description": "The Data Exploration conda environment contains libraires for ingesting, processing, and visualizing datasets. Oracle ADS (lite version) comes pre-installed to help you  ingest data from multiple data sources on OCI. You can also consume streams from the Streaming service using the kafka-python library. You can work on dataframes  using pandas, pandarallel, and dask. Use matplotlib, seaborn, plotly, and bokeh to construct visualizations of your dataset. To get started with the Data Exploration environment, review the notebook example **notebooks/explv1/getting-started.ipynb** in the **Notebook Examples launcher button**.",
      "logo": "data_exploration",
      "notebooks": ["notebooks/dataexp/"],
      "type": "data_science",
      "create_date": "Thu, Dec 10, 2020, 22:02:44  UTC",
      "size_mb": "402.14",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Data Exploration and Manipulation/1.0/explv1"]
    },
    {
      "slug": "mlcpuv1",
      "name": "General Machine Learning for CPUs",
      "version": "1.0",
      "manifest_version": "1.0",
      "arch_type": "CPU",
      "libraries": ["ADS (v2.1.0)", "Oracle AutoML (v0.5.2)", "Oracle MLX (v1.0.16)", "scikit-learn (v0.23)", "xgboost (v1.2.0)", "lightgbm (v2.3)", "TensorFlow (v2.3.1)", "category-encoders (v2.2.2)"],
      "description": "The General Machine Learning for CPUs conda environment includes libraires for data manipulation, supervised machine learning through sklearn, xgboost, lightGBM,  Keras (with TensorFlow), and Oracle AutoML. The environment also includes a model explainability library (Oracle MLX) as well as the full distribution of ADS.  This environment provides a good baseline for generic machine learning tasks and comes with multiple notebook examples to help you get started.To get started with the General Machine Learning environment, open and review the notebook example **notebooks/mlcpuv1/getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "logo": "machine_learning",
      "python": "3.6",
      "notebooks": ["notebooks/ml/1.0/"],
      "type": "data_science",
      "create_date": "Fri, Dec 11, 2020, 01:37:57  UTC",
      "size_mb": "1756.98",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/General Machine Learning for CPUs/1.0/mlcpuv1"]
    },
    {
      "arch_type": "CPU",
      "description": "The Natural Language Processing for CPU conda environment is designed for users interested in working with text datasets and performing natural language process tasks. The conda environment contains a curated list of libraries and frameworks common for natural language processing workloads. The libraries include NLTK, HuggingFace\u2019s Transformers library, various wrapper around BERT like keybert, and NLP/Deep-learning accelerating frameworks like Pytorch-Ligthning and simpletransformers. The notebook examples included with the conda environment demonstrate how to use the packages to work with text data and perform tasks such as key-phrase extraction and part-of-speech tagging. They also showcase how to use ADS\u2019 built-in text support functionalities such as data extraction from text documents in Object Storage.",
      "libraries": ["ads-lite (v2.2.1)", "pytorch-lightning (v1.2.8)", "nltk (v3.6.1)", "transformers (v4.5.1)", "eli5 (v0.11.0)", "lime (v0.2.0.1)", "simpletransformers (v0.61.4)", "umap-learn (v0.5.1)", "keybert (v0.2.0)"],
      "logo": "nlp",
      "manifest_version": "1.0",
      "name": "Natural Language Processing for CPU Python 3.7",
      "notebooks": ["notebooks/nlp_p37_cpu_v1/"],
      "python": "3.7.8",
      "slug": "nlp_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Wed, May 05, 2021, 01:46:48  UTC",
      "size_mb": "1655.93",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Natural Language Processing for CPU Python 3.7/1.0/nlp_p37_cpu_v1"]
    },
    {
      "arch_type": "CPU",
      "description": "This environment includes ads-lite, onnx, onnxruntime, and their dependencies. The purpose of this environment is to offer a test runtime for your onnx model artifacts.  `ONNX` is an open source, open model format which allows you to save a model from different ML libraires into a single, portable format that is independent of the training library.   ONNX models can be deployed through Oracle Functions or the upcoming Data Science Model Deployment feature. You can use this conda to convert models from different ML libraries  into ONNX format, including AutoML model.  You can apply ONNX runtime for inferencing.  Also, can use ONNX to plot out a graph of your machine learning model workflow. To get started with the ONNX environment, review the notebook example **getting-started.ipynb** in the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "onnx (v1.7.0)", "onnxruntime (v1.4.0)", "onnxmltools (v1.7.0)", "onnxconverter-common (v1.7.0)"],
      "logo": "onnx",
      "manifest_version": "1.0",
      "name": "Onnx for CPU Python 3.7",
      "notebooks": ["notebooks/onnx17_p37_cpu_v1/"],
      "python": "3.7",
      "slug": "onnx17_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Fri, Apr 30, 2021, 19:23:18  UTC",
      "size_mb": "404.44",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Onnx for CPU Python 3.7/1.0/onnx17_p37_cpu_v1"]
    },
    {
      "arch_type": "CPU",
      "description": "This environment includes ads-lite, onnx, onnxruntime, and their dependencies. The purpose of this environment is to offer a test runtime for your onnx model artifacts.  `ONNX` is an open source, open model format which allows you to save a model from different ML libraires into a single, portable format that is independent of the training library.   ONNX models can be deployed through Oracle Functions or the upcoming Data Science Model Deployment feature. You can use this conda to convert models from different ML libraries  into ONNX format, including AutoML model.  You can apply ONNX runtime for inferencing.  Also, can use ONNX to plot out a graph of your machine learning model workflow. To get started with the ONNX environment, review the notebook example **getting-started.ipynb** in the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.0)", "onnx (v1.7.0)", "onnxruntime (v1.4.0)", "onnxmltools (v1.7.0)", "onnxconverter-common (v1.7.0)"],
      "logo": "onnx",
      "manifest_version": "1.0",
      "name": "Onnx130 for CPU Python 3.7",
      "notebooks": ["notebooks/onnx17_p37_cpu_v1.0/"],
      "python": "3.7",
      "slug": "onnx17_p37_cpu_v1.0",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Wed, Apr 14, 2021, 08:10:27  UTC",
      "size_mb": "386.06",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Onnx130 for CPU Python 3.7/1.0/onnx17_p37_cpu_v1.0"]
    },
    {
      "arch_type": "CPU",
      "description": "Work seamlessly with Oracle databases using the ADS Connector, SQLAlchemy and ipython-sql.  Use a notebook to create ETL jobs, batch transform data and perform database queries.  The  ADS Connector provides a uniform interface to connect to databases. Use ipython-sql to directly  enter a SQL command into a cell without the need to use python in that cell. Includes support for  Oracle, MySQL and SQLite.To get started with the Database environment, review the notebook example **getting-started.ipynb**  by clicking on the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "cx-Oracle (v8.0.1)", "ipython-sql (v0.4.0)", "mysql-connector-python (v8.0.21)", "SQLAlchemy (v1.3.19)"],
      "logo": "database",
      "manifest_version": "1.0",
      "name": "Oracle Database for CPU Python 3.7",
      "notebooks": ["notebooks/database_p37_cpu_v1/"],
      "python": "3.7",
      "slug": "database_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Tue, May 04, 2021, 20:14:52  UTC",
      "size_mb": "423.02",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Oracle Database for CPU Python 3.7/1.0/database_p37_cpu_v1"]
    },
    {
      "slug": "dbv1",
      "name": "Oracle Database",
      "version": "1.0",
      "manifest_version": "1.0",
      "python": "3.6",
      "arch_type": "CPU",
      "libraries": ["ads-lite (v2.1.0)", "cx-Oracle (v8.0.1)", "ipython-sql (v0.4.0)", "mysql-connector-python (v8.0.21)", "SQLAlchemy (v1.3.19)"],
      "description": "Work seamlessly with Oracle databases using the ADS Connector, SQLAlchemy and ipython-sql.  Use a notebook to create ETL jobs, batch transform data and perform database queries.  The  ADS Connector provides a uniform interface to connect to databases. Use ipython-sql to directly  enter a SQL command into a cell without the need to use python in that cell. Includes support for  Oracle, MySQL and SQLite.To get started with the Database environment, review the notebook example **notebooks/dbv1/getting-started.ipynb**  by clicking on the **Notebook Examples launcher button**.",
      "logo": "database",
      "notebooks": ["notebooks/database/1.0/"],
      "type": "data_science",
      "create_date": "Thu, Dec 10, 2020, 23:49:13  UTC",
      "size_mb": "391.1",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Oracle Database/1.0/dbv1"]
    },
    {
      "arch_type": "CPU",
      "description": "This conda allows data scientists to leverage Apache Spark including the machine learning algorithms in MLlib. Use PySparkSQL to analyze structured and semi-structured data that is store on Object Storage. PySpark leverages the full power of a notebook session by using parallel computing. For larger jobs, you can develop Spark applications and submit them to the Data Flow service. New in this release is support for PySpark version 3.0.2. This version is compatible with the OCI Data Flow service.To get started with the PySpark environment, open and review the notebook example **getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "oraclejdk (v8)", "pyspark (v3.0.2)", "scikit-learn (v0.24.1)", "sparksql-magic (v0.0.3)"],
      "logo": "pyspark",
      "manifest_version": "2.0",
      "name": "PySpark 3.0 and Data Flow",
      "notebooks": ["notebooks/pyspark30_p37_cpu_v1/"],
      "python": "3.7",
      "slug": "pyspark30_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Wed, May 26, 2021, 21:32:50  UTC",
      "size_mb": "733.02",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/PySpark 3.0 and Data Flow/1.0/pyspark30_p37_cpu_v1"]
    },
    {
      "arch_type": "CPU",
      "description": "This conda allows data scientists to leverage Apache Spark including the machine learning algorithms in MLlib. Use PySparkSQL to analyze structured and semi-structured data that is store on Object Storage. PySpark leverages the full power of a notebook session by using parallel computing. For larger jobs, you can  develop Spark applications and submit them to the Data Flow service. New in this release is support for  compressed files, update notebooks, and a new notebook that demonstrates how to access the Oracle Object Storage  and the Autonomous Database with PySpark.To get started with the PySpark environment, open and review the notebook example **getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "oraclejdk (v8)", "pyspark (v2.4.4)", "scikit-learn (v0.24.1)", "sparksql-magic (v0.0.3)"],
      "logo": "pyspark",
      "manifest_version": "1.0",
      "name": "PySpark and Data Flow",
      "notebooks": ["notebooks/pyspark24_p37_cpu_v1/"],
      "python": "3.7",
      "slug": "pyspark24_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Fri, Apr 30, 2021, 19:23:42  UTC",
      "size_mb": "709.17",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/PySpark and Data Flow/1.0/pyspark24_p37_cpu_v1"]
    },
    {
      "arch_type": "CPU",
      "description": "The PyTorch conda environment is a machine learning library that is mainly used for applications in computer vision and natural language processing. It provides high level features for tensor computing and deep neural networks.  This environment also includes acceleration support on Intel's  CPUs with the used of daal4py. This library enhances scikit-learn algorithms by using Intel(R) oneAPI Data Analytics library. Use ads-lite to  speed up your data science workflow with tools that automate common tasks.To get started with the PyTorch environment, open and review the notebook example **getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "category-encoders (v2.2.2)", "daal4py (v2021.1)", "pandas (v1.2.3)", "scikit-learn (v0.23.2)"],
      "logo": "machine_learning",
      "manifest_version": "1.0",
      "name": "PyTorch for CPU Python 3.7",
      "notebooks": ["notebooks/pytorch18_p37_v1/"],
      "python": "3.7",
      "slug": "pytorch18_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Fri, Apr 30, 2021, 19:25:21  UTC",
      "size_mb": "4238.73",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/PyTorch for CPU Python 3.7/1.0/pytorch18_p37_cpu_v1"]
    },
    {
      "arch_type": "CPU",
      "description": "The TensorFlow conda environment is an ecosystem of tools and libraries to create state-of-the-art machine learning models. Use TensorFlow to train and deploy deep neural networks for image recognition, natural language processing, recurrent neural networks and other machine learning applications. Use the ads-lite library to speed up your data science workflow. To get started with the Tensorflow environment, open and review the notebook example **getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "category-encoders (v2.2.2)", "pandas (v1.2.3)", "scikit-learn (v0.23.2)", "tensorboard (v2.4.1)", "tensorflow (v2.3.2)"],
      "logo": "machine_learning",
      "manifest_version": "1.0",
      "name": "Tensorflow for CPU Python 3.7",
      "notebooks": ["notebooks/tensorflow23_p37_v1/"],
      "python": "3.7",
      "slug": "tensorflow23_p37_cpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Fri, Apr 30, 2021, 19:27:29  UTC",
      "size_mb": "857.6",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/Tensorflow for CPU Python 3.7/1.0/tensorflow23_p37_cpu_v1"]
    },
    {
      "name": "onnx130",
      "version": "1.0",
      "slug": "onnx13v1",
      "manifest_version": "1.0",
      "libraries": ["ads-lite (v2.1.0)", "onnx (v1.7.0)", "onnxruntime (v1.4.0)", "onnxmltools (v1.7.0)", "onnxconverter-common (v1.7.0)"],
      "description": "This environment includes ads-lite, onnx, onnxruntime, and their dependencies. The purpose of this environment is to offer a test runtime for your onnx model artifacts.  `ONNX` is an open source, open model format which allows you to save a model from different ML libraires into a single, portable format that is independent of the training library.   ONNX models can be deployed through Oracle Functions or the upcoming Data Science Model Deployment feature. You can use this conda to convert models from different ML libraries  into ONNX format, including AutoML model.  You can apply ONNX runtime for inferencing.  Also, can use ONNX to plot out a graph of your machine learning model workflow. To get started with the ONNX environment, open and review the notebook example **notebooks/onnx13v1/getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "logo": "onnx",
      "python": "3.6",
      "arch_type": "CPU",
      "notebooks": ["notebooks/onnx/1.0/"],
      "type": "data_science",
      "create_date": "Thu, Dec 10, 2020, 23:24:41  UTC",
      "size_mb": "383.3",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/onnx130/1.0/onnx13v1"]
    },
    {
      "slug": "pyspv10",
      "name": "pyspark",
      "version": "1.0",
      "manifest_version": "1.0",
      "python": "3.6",
      "arch_type": "CPU",
      "libraries": ["ads-lite (v2.1.0)", "oraclejdk (v8)", "pyspark (v2.4.4)", "scikit-learn (v0.23.2)", "sparksql-magic (v0.0.3)"],
      "description": "This conda allows data scientists to leverage Apache Spark. It can be used to access the full computational power  of a notebook session by using parallel computing. For larger jobs, you can develop Spark applications and submit them with  ADS to the Oracle Cloud Infrastructure Data Flow service without blocking the notebook session.  PySpark MLlib implements a  wide collection of machine learning algorithms. Use the SQL-like language of PySparkSQL to analyze structure and  semi-structured data stored in Oracle Cloud Infrastructure Object Storage.  To get started with the PySpark environment, open and review the notebook example **notebooks/pyspv10/getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "logo": "pyspark",
      "notebooks": ["notebooks/pyspark/1.0/"],
      "type": "data_science",
      "create_date": "Thu, Dec 10, 2020, 23:37:40  UTC",
      "size_mb": "680.5",
      "deprecated": "True",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/cpu/pyspark/1.0/pyspv10"]
    },
    {
      "slug": "classic_gpu",
      "name": "Classic GPU Notebook Session Kernel",
      "version": "1.0",
      "manifest_version": "1.0",
      "python": "3.6",
      "arch_type": "GPU",
      "deprecated": "True",
      "libraries": ["ads (v0+untagged.4506.g5075d66)", "mlx (v1.0.11)", "automl (v0.4.2)", "dask (v2.16)", "scikit-learn (v0.21.3)", "tensorflow (v2.2)", "pytorch-gpu (v1.2.0)", "mxnet-cu100 (v1.5.1)", "xgboost (v1.1.1)", "lightgbm (v2.3.0)", "pyod (v0.8.1)", "pymc3 (v3.7)"],
      "description": "This conda environment **(deprecated Oct 2021)** corresponds to the GPU notebook session available in our most recent prior release (August 2020) and will be deprecated by October 2021.  We provide this conda as a starting point to help migrate work to the other modular conda environments. There will be no further updates to this conda environment.To get started with the Classic GPU environment, open and review the notebook example **notebooks/classic_gpu/getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "logo": "v5logo_gpu",
      "root": "False",
      "notebooks": ["notebooks/v5pack/"],
      "type": "data_science",
      "create_date": "Fri, Dec 11, 2020, 01:40:59  UTC",
      "size_mb": "3483.72",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/gpu/Classic GPU Notebook Session Kernel/1.0/classic_gpu"]
    },
    {
      "slug": "mlgpuv1",
      "name": "General Machine Learning for GPUs",
      "version": "1.0",
      "manifest_version": "1.0",
      "arch_type": "GPU",
      "libraries": ["ADS (v2.1.0)", "Oracle AutoML (v0.5.2)", "Oracle MLX (v1.0.16)", "scikit-learn (v0.23)", "xgboost (v1.2.0)", "lightgbm (v2.3)", "pandas (v1.1.0)", "tensorflow (v2.3.1)"],
      "description": "The General Machine Learning conda environment includes libraires for data manipulation, supervised machine learning through sklearn, xgboost, lightGBM,  TensorFlow, and Oracle AutoML. The environment also includes a model explainability library (Oracle MLX) as well as the full distribution of ADS.  This environment provides a good baseline for generic machine learning tasks and comes with multiple notebook examples to help you get started.To get started with the General Machine Learning environment for GPUs, open and review the notebook example **notebooks/mlgpuv1/getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "logo": "machine_learning",
      "python": "3.6",
      "notebooks": ["notebooks/mlgpu/1.0/"],
      "type": "data_science",
      "create_date": "Fri, Dec 11, 2020, 00:08:34  UTC",
      "size_mb": "2621.44",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/gpu/General Machine Learning for GPUs/1.0/mlgpuv1"]
    },
    {
      "slug": "rapidsgpuv1",
      "name": "NVIDIA RAPIDS 0.16",
      "version": "1.0",
      "manifest_version": "1.0",
      "arch_type": "GPU",
      "libraries": ["cudf (v0.16)", "cuml (v0.16)", "cugraph (v0.16)", "cusignal (v0.16)", "cuspatial (v0.16)", "ads-lite (v2.1.0)", "xgboost(1.2.0)"], "description": "This environment contains the NVIDIA RAPIDS framework which includes a collection of libraries for executing end-to-end data science pipelines in the GPU. It has a familiar look and feel to scikit-learn and pandas. RAPIDS include libraries such as cuDF, cuML, and cuGraph. In addition to the NVIDIA RAPIDS libraries, we also included ADS in the environment. To get started with the RAPIDs environment, review the notebook example **notebooks/rapidsgpuv1/getting-started.ipynb** in the **Notebook Examples launcher button**.",
      "logo": "rapids",
      "python": "3.7",
      "notebooks": ["notebooks/rapidsgpu/1.0/"],
      "type": "data_science",
      "create_date": "Fri, Dec 11, 2020, 00:52:17  UTC",
      "size_mb": "3324.51",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/gpu/NVIDIA RAPIDS 0.16/1.0/rapidsgpuv1"]
    },
    {
      "arch_type": "GPU",
      "description": "The Natural Language Processing for GPU conda environment is designed for users interested in working with text datasets and performing natural language process tasks. The conda environment contains a curated list of libraries and frameworks common for natural language processing workloads. The libraries include NLTK, HuggingFace\u2019s Transformers library, various wrapper around BERT like keybert, and NLP/Deep-learning accelerating frameworks like Pytorch-Ligthning and simpletransformers. The notebook examples included with the conda environment demonstrate how to use the packages to work with text data and perform tasks such as key-phrase extraction and part-of-speech tagging. They also showcase how to use ADS\u2019 built-in text support functionalities such as data extraction from text documents in Object Storage.",
      "libraries": ["ads-lite (v2.2.1)", "pytorch-lightning (v1.2.8)", "nltk (v3.6.1)", "transformers (v4.5.1)", "eli5 (v0.11.0)", "lime (v0.2.0.1)", "simpletransformers (v0.61.4)", "umap-learn (v0.5.1)", "keybert (v0.2.0)"],
      "logo": "nlp",
      "manifest_version": "1.0",
      "name": "Natural Language Processing for GPU Python 3.7",
      "notebooks": ["notebooks/nlp_p37_gpu_v1/"],
      "python": "3.7.8",
      "slug": "nlp_p37_gpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Wed, May 05, 2021, 01:48:55  UTC",
      "size_mb": "3464.99",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/gpu/Natural Language Processing for GPU Python 3.7/1.0/nlp_p37_gpu_v1"]
    },
    {
      "arch_type": "GPU",
      "description": "The PyTorch conda environment is a machine learning library that is mainly used for applications in computer vision and natural language processing. It provides high level features for tensor computing and deep neural networks. The environment also includes libraries for data manipulation, supervised machine learning through sklearn, xgboost and ads-lite.  This environment provides a good baseline for generic machine learning tasks and comes with multiple notebook examples to help you get started.To get started with the PyTorch environment for GPUs, open and review the notebook example **getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "PyTorch (v1.8.1)", "scikit-learn (v0.23.2)", "xgboost (v1.3.0)", "pandas (v1.2.3)"],
      "logo": "machine_learning",
      "manifest_version": "1.0",
      "name": "PyTorch for GPU Python 3.7",
      "notebooks": ["notebooks/pytorch18_p37_gpu_v1/"],
      "python": "3.7",
      "slug": "pytorch18_p37_gpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Tue, May 04, 2021, 22:20:46  UTC",
      "size_mb": "2551.11",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/gpu/PyTorch for GPU Python 3.7/1.0/pytorch18_p37_gpu_v1"]
    },
    {
      "arch_type": "GPU",
      "description": "The TensorFlow conda environment is an ecosystem of tools and libraries to create state-of-the-art machine learning models. Use  TensorFlow to train and deploy deep neural networks for image recognition, natural language processing, recurrent neural networks  and other machine learning applications. Use the ads-lite library to speed up your data science workflow.To get started with the TensorFlow environment for GPUs, open and review the notebook example **getting-started.ipynb** by clicking on the **Notebook Examples launcher button**.",
      "libraries": ["ads-lite (v2.2.1)", "category-encoders (v2.2.2)", "pandas (v1.2.3)", "scikit-learn (v0.23.2)", "tensorboard (v2.4.1)", "tensorflow (v2.3.2)"],
      "logo": "machine_learning",
      "manifest_version": "1.0",
      "name": "TensorFlow for GPU Python 3.7",
      "notebooks": ["notebooks/tensorflow23_p37_gpu_v1/"],
      "python": "3.7", "slug": "tensorflow23_p37_gpu_v1",
      "type": "data_science",
      "version": "1.0",
      "create_date": "Tue, May 04, 2021, 22:22:29  UTC",
      "size_mb": "1627.98",
      "pack_path": ["oci://service_conda_packs@ociodscdev/service_pack/gpu/TensorFlow for GPU Python 3.7/1.0/tensorflow23_p37_gpu_v1"]
    }
  ]
}
