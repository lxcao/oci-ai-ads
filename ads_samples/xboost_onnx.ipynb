{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=gray>Oracle Cloud Infrastructure Data Science Sample Notebook\n",
    "\n",
    "Copyright (c) 2021 Oracle, Inc.  All rights reserved. <br>\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying an XGBoost Model with Model Deployment \n",
    "\n",
    "In this tutorial we are going to prepare and save an xgboost model artifact using the `ADSModel` `prepare()` method and deploy the model as an HTTP endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites to Running this Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We recommend that you run this notebook in a notebook session using the **Data Science Conda Environment \"General Machine Learning for CPU (v1.0)\"** \n",
    "* You need access to the public internet\n",
    "* Upgrade the current version of the OCI Python SDK (`oci`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci\n",
    "import ads\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import warnings\n",
    "from os import path\n",
    "from ads.common.model import ADSModel\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.dataset.dataset_browser import DatasetBrowser\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "ads.set_documentation_mode(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to train a simple XGBoost classifier on the breast cancer dataset included in sklearn; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train xgboost model\n",
    "breast_cancer = DatasetBrowser.sklearn().open('breast_cancer').set_target(\"target\")\n",
    "train, test = breast_cancer.train_test_split(test_size=0.15)\n",
    "xgb_clf = XGBClassifier().fit(train.X.values, train.y)\n",
    "xgb_bin_model = ADSModel.from_estimator(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the \"General Machine Learning for CPU\" Data Science conda environment. Since we don't modify the conda environment we don't need to publish it. We can use \"General Machine learning for CPU (v1.0)\" for model deployment as well. Thus we'll set `data_science_env=True` when preparing the artifact with ADS. \n",
    "\n",
    "Here we are using the `prepare()` method on an `ADSModel` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model artifact template\n",
    "path_to_model_artifacts = \"xboost_artifacts\"\n",
    "model_artifact = xgb_bin_model.prepare(path_to_model_artifacts,\n",
    "                                       force_overwrite=True,\n",
    "                                       data_sample=test,\n",
    "                                       fn_artifact_files_included=False,\n",
    "                                       data_science_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the artifact template files that ADS generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the template files\n",
    "print(f\"Model Artifact Path: {path_to_model_artifacts}\\n\\nModel Artifact Files:\")\n",
    "for file in os.listdir(path_to_model_artifacts):\n",
    "    if path.isdir(path.join(path_to_model_artifacts, file)):\n",
    "        for file2 in os.listdir(path.join(path_to_model_artifacts, file)):\n",
    "            print(path.join(file, file2))\n",
    "    else:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the artifact before saving it to the model catalog and verify that the predictions made on a sample data match what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate predicion\n",
    "model_artifact.predict(data=test.X[:5], model=model_artifact.load_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the model to the catalog: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.environ['PROJECT_OCID'] \n",
    "compartment_id = os.environ['NB_SESSION_COMPARTMENT_OCID']\n",
    "\n",
    "mc_model = model_artifact.save(\n",
    "    project_id=project_id, compartment_id=compartment_id, \n",
    "    display_name=\"XGB_model (Model Deployment Test)\",\n",
    "    description=\"Testing XGB_model Model Deployment\",\n",
    "    ignore_pending_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model metadata, including its OCID value (`id`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print published model information\n",
    "mc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model with Model Deployment\n",
    "\n",
    "We are ready to deploy `mc_model`. We are using the user principal (config+key) method of authentication. Alternatively you can use resource principal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting OCI config information\n",
    "oci_config = oci.config.from_file(\"~/.oci/config\", \"DEFAULT\")\n",
    "# Setting up DataScience instance\n",
    "data_science = oci.data_science.DataScienceClient(oci_config)\n",
    "# Setting up data science composite client to unlock wait_for_state operations\n",
    "data_science_composite = oci.data_science.DataScienceClientCompositeOperations(data_science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model deployment configuration object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepareing model deployment data\n",
    "model_deployment_details = {\n",
    "    \"displayName\": \"XGB model test - ONNX\",\n",
    "    \"projectId\": mc_model.project_id,\n",
    "    \"compartmentId\": mc_model.compartment_id,\n",
    "    \"modelDeploymentConfigurationDetails\": {\n",
    "        \"deploymentType\": \"SINGLE_MODEL\",\n",
    "        \"modelConfigurationDetails\": {\n",
    "            \"modelId\": mc_model.id,\n",
    "            \"instanceConfiguration\": {\n",
    "                \"instanceShapeName\": \"VM.Standard2.4\"\n",
    "            },\n",
    "            \"scalingPolicy\": {\n",
    "                \"policyType\": \"FIXED_SIZE\",\n",
    "                \"instanceCount\": 2\n",
    "            },\n",
    "            \"bandwidthMbps\": 10\n",
    "        }\n",
    "    },\n",
    "    \"categoryLogDetails\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to deploy. This takes a few minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_deployment = data_science_composite.create_model_deployment_and_wait_for_state(model_deployment_details,\n",
    "                                                                                     wait_for_states=[\"SUCCEEDED\",\n",
    "                                                                                                      \"FAILED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure our deployment was successful: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grabbing the model deployment ocid...\")\n",
    "model_deployment_data = json.loads(str(model_deployment.data))\n",
    "model_deployment_id = model_deployment_data['resources'][0]['identifier']\n",
    "print(f\"Model deployment ocid: {model_deployment_id}\")\n",
    "\n",
    "# check if the model deployment was successful: \n",
    "assert model_deployment.status == 200, f\"Model deployment issued an HTTP error code: {model_deployment.status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model deployment was unsuccessful, we recommend that you follow the Troubleshooting guide in our service documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the Model Deployment `/predict` Endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we want to invoke the `/predict` endpoint of the deployed model and make inferences on a batch of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can execute the cell below, copy and paste the URI of your model deployment. You can find that value in the OCI console under the detail page of your model deployment. In the **Resources** menu of the detail page, click on **\"Invoking Your Model\"**. You will find the HTTP endpoint of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = f\"<replace-with-your-model-deployment-uri>\"\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_rps = False\n",
    "\n",
    "# payload: \n",
    "input_data = train.X[:5].to_json()\n",
    "\n",
    "if using_rps: # using resource principal:     \n",
    "    auth = oci.auth.signers.get_resource_principals_signer()\n",
    "else: # using config + key: \n",
    "    config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n",
    "    auth = Signer(\n",
    "        tenancy=config['tenancy'],\n",
    "        user=config['user'],\n",
    "        fingerprint=config['fingerprint'],\n",
    "        private_key_file_location=config['key_file'],\n",
    "        pass_phrase=config['pass_phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "# submit request to model endpoint: \n",
    "response = requests.post(uri, json=input_data, auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the status code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the model predictions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlcpuv1]",
   "language": "python",
   "name": "conda-env-mlcpuv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
