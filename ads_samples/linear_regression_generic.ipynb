{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=gray>Oracle Cloud Infrastructure Data Science Sample Notebook\n",
    "\n",
    "Copyright (c) 2021 Oracle, Inc.  All rights reserved. <br>\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Simple Sklearn Linear Regression Model\n",
    "\n",
    "In this tutorial we are going to prepare and save an sklearn model artifact using the ADS generic method and deploy the model as an HTTP endpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites to Running this Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We recommend that you run this notebook in a notebook session using the **Data Science Conda Environment \"General Machine Learning for CPU (v1.0)\"** \n",
    "* You need access to the public internet\n",
    "* **Upgrade the current version of the OCI Python SDK** (`oci`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci\n",
    "import ads\n",
    "import json\n",
    "import joblib\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import warnings\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from ads.common.model_export_util import prepare_generic_model\n",
    "import time\n",
    "import cloudpickle\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "ads.set_documentation_mode(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to load a simple dataset about the housing market in the US and predict the house price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"https://objectstorage.us-ashburn-1.oraclecloud.com/n/bigdatadatasciencelarge/b/hosted-ds-datasets/o/others%2Fusa_housing_lite.csv\")\n",
    "X = ds[['avg_area_income', 'avg_area_house_age', 'avg_area_number_of_rooms',\n",
    "        'avg_area_number_of_bedrooms', 'area_population']]\n",
    "y = ds['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn `LinearRegression()` algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LinearRegression().fit(X_train, y_train)\n",
    "lrm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the \"General Machine Learning for CPU\" Data Science conda environment. Since we don't modify the conda environment we don't need to publish it. We can use \"General Machine learning for CPU (v1.0)\" for model deployment as well. Thus we'll set `data_science_env=True` when preparing the artifact with ADS. \n",
    "\n",
    "Here we are using the `prepare_generic_model()` method to prepare the artifact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model artifact template\n",
    "path_to_model_artifacts = \"linear_regression_generic_artifacts\"\n",
    "generic_model_artifact = prepare_generic_model(\n",
    "    path_to_model_artifacts, \n",
    "    force_overwrite=True,\n",
    "    function_artifacts=False,\n",
    "    data_science_env=True)\n",
    "\n",
    "# Serialize the model\n",
    "with open(path.join(path_to_model_artifacts, \"model.pkl\"), \"wb\") as outfile:\n",
    "    cloudpickle.dump(lrm, outfile)\n",
    "\n",
    "# List the template files\n",
    "print(f\"Model Artifact Path: {path_to_model_artifacts}\\n\\nModel Artifact Files:\")\n",
    "for file in os.listdir(path_to_model_artifacts):\n",
    "    if path.isdir(path.join(path_to_model_artifacts, file)):\n",
    "        for file2 in os.listdir(path.join(path_to_model_artifacts, file)):\n",
    "            print(path.join(file, file2))\n",
    "    else:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make a few changes to the `score.py` template that ADS generates. We are simply uncommenting the following three lines in `predict()` : \n",
    "\n",
    "```\n",
    "    # from pandas import read_json, DataFrame\n",
    "    # from io import StringIO\n",
    "    # X = read_json(StringIO(data)) if isinstance(data, str) else DataFrame.from_dict(data)\n",
    "```\n",
    "and changing `data` for `X` in `model.predict()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {path_to_model_artifacts}/score.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "from cloudpickle import cloudpickle\n",
    "\n",
    "\n",
    "model_name = 'model.pkl'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   Inference script. This script is used for prediction by scoring server when schema is known.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_model(model_file_name=model_name):\n",
    "    \"\"\"\n",
    "    Loads model from the serialized format\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model:  a model instance on which predict API can be invoked\n",
    "    \"\"\"\n",
    "    model_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    contents = os.listdir(model_dir)\n",
    "    if model_file_name in contents:\n",
    "        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), model_file_name), \"rb\") as file:\n",
    "            return cloudpickle.load(file)\n",
    "    else:\n",
    "        raise Exception('{0} is not found in model directory {1}'.format(model_file_name, model_dir))\n",
    "\n",
    "\n",
    "def predict(data, model=load_model()):\n",
    "    \"\"\"\n",
    "    Returns prediction given the model and data to predict\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Model instance returned by load_model API\n",
    "    data: Data format as expected by the predict API of the core estimator. For eg. in case of sckit models it could be numpy array/List of list/Panda DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions: Output from scoring server\n",
    "        Format: {'prediction':output from model.predict method}\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    from pandas import read_json, DataFrame\n",
    "    from io import StringIO\n",
    "    X = read_json(StringIO(data)) if isinstance(data, str) else DataFrame.from_dict(data)\n",
    "    return {'prediction':model.predict(X).tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.environ['PROJECT_OCID'] \n",
    "compartment_id = os.environ['NB_SESSION_COMPARTMENT_OCID']\n",
    "\n",
    "mc_model = generic_model_artifact.save(project_id=project_id,\n",
    "                                       compartment_id=compartment_id,\n",
    "                                       display_name=\"USA Housing Lin Reg (Model Deployment Test) - Generic\",\n",
    "                                       description=\"Testing USA Housing Lin Reg model (Generic) deployment\",\n",
    "                                       ignore_pending_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print published model information\n",
    "mc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the model with Model Deployment\n",
    "\n",
    "We are ready to deploy `mc_model`. We are using the user principal (config+key) method of authentication. Alternatively you can use resource principal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting OCI config information\n",
    "# oci_config = pd.read_csv(\"/home/datascience/.oci/config\", delimiter=\"=\", header = 0).to_dict()['[DEFAULT]']\n",
    "oci_config = oci.config.from_file(\"~/.oci/config\", \"DEFAULT\")\n",
    "# Setting up DataScience instance\n",
    "data_science = oci.data_science.DataScienceClient(oci_config)\n",
    "# Setting up data science composite client to unlock wait_for_state operations\n",
    "data_science_composite = oci.data_science.DataScienceClientCompositeOperations(data_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepareing model deployment data\n",
    "model_deployment_details = {\n",
    "    \"displayName\": \"Model Deployment NB Test USA Housing Lin Reg - PKL\",\n",
    "    \"projectId\": mc_model.project_id,\n",
    "    \"compartmentId\": mc_model.compartment_id,\n",
    "    \"modelDeploymentConfigurationDetails\": {\n",
    "        \"deploymentType\": \"SINGLE_MODEL\",\n",
    "        \"modelConfigurationDetails\": {\n",
    "            \"modelId\": mc_model.id,\n",
    "            \"instanceConfiguration\": {\n",
    "                \"instanceShapeName\": \"VM.Standard2.4\"\n",
    "            },\n",
    "            \"scalingPolicy\": {\n",
    "                \"policyType\": \"FIXED_SIZE\",\n",
    "                \"instanceCount\": 1\n",
    "            },\n",
    "            \"bandwidthMbps\": 10\n",
    "        }\n",
    "    },\n",
    "    \"categoryLogDetails\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deploy the model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "model_deployment = data_science_composite.create_model_deployment_and_wait_for_state(model_deployment_details,\n",
    "                                                                                     wait_for_states=[\"SUCCEEDED\",\n",
    "                                                                                                      \"FAILED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell extract from the `model_deployment` object a series of useful diagnostics about the creation of the model deployment resource: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grabbing the model deployment ocid...\")\n",
    "model_deployment_data = json.loads(str(model_deployment.data))\n",
    "model_deployment_id = model_deployment_data['resources'][0]['identifier']\n",
    "print(f\"Model deployment ocid: {model_deployment_id}\")\n",
    "\n",
    "print(\"Checking for the correct response status code...\")\n",
    "if model_deployment.status == 200:\n",
    "    print(f\"Work request status code returned: {model_deployment.status}\")\n",
    "    print(\"Checking for non-empty response data...\")\n",
    "    if model_deployment.data:\n",
    "        print(f\"Data returned: {model_deployment.data}\")\n",
    "        print(\"Grabbing the model deployment work request status...\")\n",
    "        work_request_status = model_deployment_data['status']\n",
    "        print(\"Checking for the correct work request status...\")\n",
    "        if work_request_status == \"SUCCEEDED\":\n",
    "            print(f\"Work request status returned: {work_request_status}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"Work request returned an incorrect status of: {work_request_status}\")\n",
    "            print(\n",
    "                f\"Work requests error: {data_science.list_work_request_errors(model_deployment.data.id).data}\")\n",
    "            print(\n",
    "                f\"opc-request-id: {model_deployment.headers['opc-request-id']}\")\n",
    "    else:\n",
    "        print(\"Failed to grab model deployment data.\")\n",
    "        print(f\"opc-request-id: {model_deployment.headers['opc-request-id']}\")\n",
    "else:\n",
    "    print(\n",
    "        f\"Model deployment returned an incorrect status of: { model_deployment.status}\")\n",
    "    print(f\"opc-request-id: {model_deployment.headers['opc-request-id']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to invoke the model `/predict` endpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the Model Deployment `/predict` Endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we want to invoke the `/predict` endpoint of the deployed model and make inferences on a batch of new data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can execute the cell below, copy and paste the URI of your model deployment. You can find that value in the OCI console under the detail page of your model deployment. In the **Resources** menu of the detail page, click on **\"Invoking Your Model\"**. You will find the HTTP endpoint of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = f\"\"\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a notebook session, you have two options to authenticate to the model deployment `/predict` endpoint: with user principal (config+key) or with resource principal. We are using user principal. If you prefer to use resource principal, set `using_rps=True` : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using resource princital to authenticate to the /predict endpoint: \n",
    "using_rps = False\n",
    "\n",
    "# payload: \n",
    "input_data = X_train[:5].to_json()\n",
    "\n",
    "if using_rps: # using resource principal:     \n",
    "    auth = oci.auth.signers.get_resource_principals_signer()\n",
    "else: # using user principal (config+key): \n",
    "    config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n",
    "    auth = Signer(\n",
    "        tenancy=config['tenancy'],\n",
    "        user=config['user'],\n",
    "        fingerprint=config['fingerprint'],\n",
    "        private_key_file_location=config['key_file'],\n",
    "        pass_phrase=config['pass_phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "# submit request to model endpoint: \n",
    "response = requests.post(uri, json=input_data, auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the status code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the model predictions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlcpuv1]",
   "language": "python",
   "name": "conda-env-mlcpuv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
